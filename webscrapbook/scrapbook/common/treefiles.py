import os, json, re
from collections import OrderedDict
from itertools import count
from .util import (
    remove_prefix,
    remove_suffix,
    remove_lines,
    parse_json,
    Memoize,
    find_regex_file,
    write_file,
    delete_file,
    file_exists,
    get_number_suffix,
    SimpleObject,
    merge_dictionaries,
    split_dictionary,
)
from .tree import (
    Toc,
    Meta,
)


class TreeFiles:

    def __init__(self, scrapbook_dir):
        self._set_file_constants()

        self._scrapbook_dir = os.path.expanduser(scrapbook_dir)
        self._tree_dir      = os.path.join(self._scrapbook_dir, 'tree/')
        
        self._valid_scrapbook_dir()
        self.load_files()


    def _set_file_constants(self):
        # Constants
        self._constants = SimpleObject()

        self._constants.TOC_REGEX      = str(r"^toc([0-9]*)\.js$")
        self._constants.META_REGEX     = str(r"^meta([0-9]*)\.js$")
        self._constants.FULLTEXT_REGEX = str(r"^fulltext([0-9]*)\.js$")

        self._constants.TOC_TEMPLATE      = str("toc{}.js")
        self._constants.META_TEMPLATE     = str("meta{}.js")
        self._constants.FULLTEXT_TEMPLATE = str("fulltext{}.js")

        # .+? is .+ that matches the fewest characters, ? makes the .+ non-greedy
        # [\s\S] matches any character
        # TODO: this will wrongly match if '})' is found after the actual json content
        self._constants.FILE_CONTENT_REGEX      = str(r"scrapbook\..+?\((\{[\s\S]*\})\)")

        self._constants.TOC_CONTENT_TEMPLATE      = "/**\n * Feel free to edit this file, but keep data code valid JSON format.\n */\nscrapbook.toc({})"
        self._constants.META_CONTENT_TEMPLATE     = "/**\n * Feel free to edit this file, but keep data code valid JSON format.\n */\nscrapbook.meta({})"
        self._constants.FULLTEXT_CONTENT_TEMPLATE = "/**\n * This file is generated by WebScrapBook and is not intended to be edited.\n */\nscrapbook.fulltext({})"

        self.files = SimpleObject()


    def _valid_scrapbook_dir(self):
        ''' 
        raises exceptions if scrapbook directory is invalid and get filepaths for necessary files
        '''
        if not os.path.isdir(self._tree_dir):
            raise Exception(self._tree_dir + ' is not a scrapbook directory')


    # Parse and load files
    ###############################################################################

    @staticmethod
    def _json_preprocessing(FILE_CONTENT_REGEX):
        def preprocessing(file):
            text = file.read()
            m = re.search(FILE_CONTENT_REGEX, text)
            if m:
                return  m.group(1)
            else:
                raise Exception("Json content not found in tree file.")
        return preprocessing


    @staticmethod
    def _get_merged_files(directory, regex, no_files_found_message, load_func, files_must_exist=True):
        '''
            Merge contents of many files into a single dictionary.
            Merge all files in directory which match the regex.
            Files are merged where higher number files have a higher precedence.

            return (dictionary of merged files, modify time)
        '''

        def get_merged_files_modify_time(filepaths):
            ''' return most recent modify time of a list of filepaths 
                if no filepaths given return 0
            '''
            modify_times = [os.stat(f).st_mtime for f in filepaths] or [0]
            return max(modify_times)

        def get_filename_no_ext(filepath):
            return os.path.splitext(os.path.basename(filepath))[0]

        def sort_files_by_number(file_filenumbers):
            ''' large numbers later so they are merged later with precedence '''
            file_filenumbers.sort(key= lambda f: f[1])

        def get_filepaths_sorted_by_number_suffix(filepaths):
            file_filenames = [(file, get_filename_no_ext(file)) for file in filepaths]
            file_filenumbers = [(file, get_number_suffix(filename)) for file, filename in file_filenames]
            sort_files_by_number(file_filenumbers)
            return [f[0] for f in file_filenumbers]

        filepaths = find_regex_file(directory, regex, no_files_found_message, files_must_exist)
        ordered_files = get_filepaths_sorted_by_number_suffix(filepaths)
        file_dictionaries = [load_func(file) for file in ordered_files]
        return (merge_dictionaries(file_dictionaries), get_merged_files_modify_time(filepaths))
    
    def _load_toc(self):
        def load_toc_file(file):
            return parse_json(file,
                            self._json_preprocessing(self._constants.FILE_CONTENT_REGEX))

        data, modify_time = self._get_merged_files(
            self._tree_dir,
            self._constants.TOC_REGEX,
            'No toc file found in scrapbook directory matching the regex: ' + self._constants.TOC_REGEX,
            load_toc_file)
        self.files.toc = SimpleObject()
        self.files.toc.data = Toc(data)
        self.files.toc.modify_time = modify_time


    def _load_meta(self):
        def load_meta_file(file):
            return parse_json(file,
                            self._json_preprocessing(self._constants.FILE_CONTENT_REGEX))

        data, modify_time = self._get_merged_files(
            self._tree_dir,
            self._constants.META_REGEX,
            'No toc file found in scrapbook directory matching the regex: ' + self._constants.META_REGEX,
            load_meta_file)
        self.files.meta = SimpleObject()
        self.files.meta.data = Meta(data)
        self.files.meta.modify_time = modify_time


    def _load_fulltext(self):
        def load_fulltext_file(file):
            return parse_json(file,
                            self._json_preprocessing(self._constants.FILE_CONTENT_REGEX))

        data, modify_time = self._get_merged_files(
            self._tree_dir,
            self._constants.FULLTEXT_REGEX,
            'No fulltext file found in scrapbook directory matching the regex: ' + self._constants.FULLTEXT_REGEX,
            load_fulltext_file,
            False)
        self.files.fulltext = SimpleObject()
        self.files.fulltext.data = data
        self.files.fulltext.modify_time = modify_time
        
    def load_files(self):
        ''' load all necessary files for scrapbook '''
        self._load_toc()
        self._load_meta()
        self._load_fulltext()


    # Write files
    ###############################################################################

    def _write_split_files(self, dictionary: dict, max_size, FILENAME_FORMAT, preprocessing=lambda x:x, entry_size_calc=lambda x:1):
        '''
            Split dictionary and write each portion to a separate numbered file.
            After writing the files, delete stale numbered files
        '''
        def write_split_files(dictionaries):
            for i, dictionary  in enumerate(dictionaries):
                write_file(
                    self._tree_dir,
                    FILENAME_FORMAT.format(i if i != 0 else ''),
                    preprocessing(json.dumps(dictionary, indent=' '))
                )

        def delete_old_split_files(start_num):
            ''' start deleting numbered files from given start_num '''
            for i in count(start_num):
                if file_exists(self._tree_dir, FILENAME_FORMAT.format(i)):
                    delete_file(self._tree_dir, FILENAME_FORMAT.format(i))
                else:
                    break

        dictionaries = split_dictionary(dictionary, max_size, entry_size_calc)
        write_split_files(dictionaries)
        # wrote [0,len(dictionary)-1] files so delete [len(dictionary),âˆž] files
        delete_old_split_files(len(dictionaries))


    def write_toc(self):
        def toc_entry_size(val):
            return len(val)

        def toc_preprocessing(string):
                return self._constants.TOC_CONTENT_TEMPLATE.format(string)
        
        # A javascript string >= 256 MiB (UTF-16 chars) causes an error
        # in the browser. Split each js file at around 4 M entries to
        # prevent the issue. (An entry is mostly < 32 bytes)
        max_size = 4 * 1024 * 1024
        self._write_split_files(
            self.files.toc.data.get_data(),
            max_size,
            self._constants.TOC_TEMPLATE,
            toc_preprocessing,
            toc_entry_size
        )

    def write_meta(self):
        def meta_preprocessing(string):
                return self._constants.META_CONTENT_TEMPLATE.format(string)
        
        # A javascript string >= 256 MiB (UTF-16 chars) causes an error
        # in the browser. Split each js file at around 256 K items to
        # prevent the issue. (An item is mostly < 512 bytes)
        max_size = 256 * 1024
        self._write_split_files(
            self.files.meta.data.get_data(),
            max_size,
            self._constants.META_TEMPLATE,
            meta_preprocessing
        )

    def write_fulltext(self):
        def fulltext_entry_size(val):
            return len(val)

        def fulltext_preprocessing(string):
                return self._constants.FULLTEXT_CONTENT_TEMPLATE.format(string)
        
        # A javascript string >= 256 MiB (UTF-16 chars) causes an error
        # in the browser. Split each js file at around 4 M entries to
        # prevent the issue. (An entry is mostly < 32 bytes)
        max_size = 128 * 1024 * 1024
        self._write_split_files(
            self.files.fulltext.data,
            max_size,
            self._constants.FULLTEXT_TEMPLATE,
            fulltext_preprocessing,
            fulltext_entry_size
        )

    def write_files(self):
        self.write_toc()
        self.write_meta()
        self.write_fulltext()