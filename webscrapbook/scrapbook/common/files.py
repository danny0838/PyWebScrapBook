import os, json
from collections import OrderedDict
from .util import (
    remove_prefix,
    remove_suffix,
    remove_lines,
    parse_json,
    Memoize,
    find_regex_file,
    get_filename_no_ext,
    get_number_suffix,
    SimpleObject,
    merge_dictionaries
)


class Files:

    def __init__(self, scrapbook_dir):
        self.__set_file_constants()

        self.__scrapbook_dir = os.path.expanduser(scrapbook_dir)
        self.__tree_dir      = os.path.join(self.__scrapbook_dir, 'tree/')
        
        self.__valid_scrapbook_dir()
        self.load_files()


    def __set_file_constants(self):
        # Constants
        self.__constants = SimpleObject()

        self.__constants.TOC_REGEX      = str(r"^toc([0-9]*)\.js$")
        self.__constants.META_REGEX     = str(r"^meta([0-9]*)\.js$")
        self.__constants.FULLTEXT_REGEX = str(r"^fulltext([0-9]*)\.js$")

        self.__constants.TOC_COMMENT      = "/** \n * Feel free to edit this file, but keep data code valid JSON format.\n */\n"
        self.__constants.META_COMMENT     = self.__constants.TOC_COMMENT
        self.__constants.FULLTEXT_COMMENT = "/**\n * This file is generated by WebScrapBook and is not intended to be edited.\n */\n"

        self.__constants.TOC_PREFIX       = "scrapbook.toc("
        self.__constants.META_PREFIX      = "scrapbook.meta("
        self.__constants.FULLTEXT_PREFIX  = "scrapbook.fulltext("

        self.__constants.TOC_SUFFIX       = ")"
        self.__constants.META_SUFFIX      = self.__constants.TOC_SUFFIX
        self.__constants.FULLTEXT_SUFFIX  = self.__constants.TOC_SUFFIX

        self.files = SimpleObject()


    def __valid_scrapbook_dir(self):
        ''' 
        raises exceptions if scrapbook directory is invalid and get filepaths for necessary files
        '''
        try:
            os.path.isdir(self.__tree_dir)
        except:
            raise Exception('Current working directory is not a scrapbook directory')


    def write_toc(self, toc: dict):
        # def backup_toc():
        # # TODO: improve backup
        #     try:
        #         os.rename(self._toc_file, self._toc_file + '.bak')
        #     except:
        #         raise Exception('Could not backup ' + self._toc_file + ' before writing')

        # def write_new_toc(toc):
        #     def toc_preprocessing(toc):
        #         return self.TOC_COMMENT + self.TOC_PREFIX + json.dumps(toc) + self.TOC_SUFFIX
        #     with open(self._toc_file, "w") as file:
        #         file.write(
        #             toc_preprocessing(json.dumps(toc))
        #         )
        # backup_toc()
        # write_new_toc(toc)
        pass


    # Parse and load files
    ###############################################################################

    @staticmethod
    def __json_preprocessing(comment_lines, prefix, suffix):
        def preprocessing(file):
            remove_lines(file, comment_lines)
            return remove_suffix(
                        remove_prefix(file.read().strip(), prefix), suffix)
        return preprocessing


    @staticmethod
    def __get_merged_dictionaries_on_filename_precedence(directory, regex, no_match_message, load_func):
        '''
            merge all files in directory which match the glob and 
            merge them in order of highest number before the file extension first
        '''
        def sort_files_by_number(file_filenumbers):
            ''' large numbers later so they are merged later with precedence '''
            file_filenumbers.sort(key= lambda f: f[1])

        file_filenames = [ (file, get_filename_no_ext(file)) for file in find_regex_file(directory, regex, no_match_message) ]
        file_filenumbers = [ (file, get_number_suffix(filename)) for file, filename in file_filenames ]
        sort_files_by_number(file_filenumbers)
        ordered_files = [f[0] for f in file_filenumbers]
        file_dictionaries = [ load_func(file) for file in ordered_files]
        return merge_dictionaries(file_dictionaries)
    
    def __load_toc(self):
        def load_toc_file(file):
            return parse_json(file,
                            self.__json_preprocessing(3, self.__constants.TOC_PREFIX, self.__constants.TOC_SUFFIX))
        self.files.toc = self.__get_merged_dictionaries_on_filename_precedence(
            self.__tree_dir,
            self.__constants.TOC_REGEX,
            'No toc file found in scrapbook directory matching the regex: ' + self.__constants.TOC_REGEX,
            load_toc_file)

    def __load_meta(self):
        def load_meta_file(file):
            return parse_json(file,
                            self.__json_preprocessing(3, self.__constants.META_PREFIX, self.__constants.META_SUFFIX))
        self.files.meta = self.__get_merged_dictionaries_on_filename_precedence(
            self.__tree_dir,
            self.__constants.META_REGEX,
            'No toc file found in scrapbook directory matching the regex: ' + self.__constants.META_REGEX,
            load_meta_file)

    def __load_fulltext(self):
        def load_fulltext_file(file):
            return parse_json(file,
                            self.__json_preprocessing(3, self.__constants.FULLTEXT_PREFIX, self.__constants.FULLTEXT_SUFFIX))
        self.files.fulltext = self.__get_merged_dictionaries_on_filename_precedence(
            self.__tree_dir,
            self.__constants.FULLTEXT_REGEX,
            'No fulltext file found in scrapbook directory matching the regex: ' + self.__constants.FULLTEXT_REGEX,
            load_fulltext_file)
        
    def load_files(self):
        ''' load all necessary files for scrapbook '''
        self.__load_toc()
        self.__load_meta()
        self.__load_fulltext()